{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage\n",
    "import glob\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images #Raju: change to \"visualize\"\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import custom #Raju: for bridge change it to \"custom\" \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "custom_WEIGHTS_PATH = \"C:/Users/mk5n2/Mask_RCNN/logs/resnet50_train_1/mask_rcnn_roi_0060.h5\"  # weight of train_1 (40imgs)\n",
    "# custom_WEIGHTS_PATH = \"C:/Users/mk5n2/logs/resnet50_train_2/mask_rcnn_roi_0100.h5\"  # weight of 1st iteration (97imgs)\n",
    "# custom_WEIGHTS_PATH = \"C:/Users/mk5n2/logs/resnet50_train_1_supervised/mask_rcnn_roi_0100.h5\" # supervised\n",
    "# custom_WEIGHTS_PATH = \"C:/Users/mk5n2/logs/supervised_train_1_small_data/mask_rcnn_roi_0100.h5\" # supervised_small_data\n",
    "# custom_WEIGHTS_PATH = \"C:/Users/mk5n2/logs/roi20190401T1756/mask_rcnn_roi_0080.h5\" # 80% + 20% semi + sup\n",
    "# custom_WEIGHTS_PATH = \"C:/Users/mk5n2/logs/roi20190330T1903/mask_rcnn_roi_0120.h5\" # 2nd iteration (semi-supervised)(133 imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = custom.CustomConfig() #Raju: for bridge change \"custom_matc\" to \"custom\"\n",
    "custom_DIR = os.path.join(ROOT_DIR, \"customImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "# Here, two parameters we should change\n",
    "# 1. backbone: resnet 50, resnet101-- from config.py\n",
    "# 2. Detection_Min_Confidence: 0.5/0.9,... ... --from config.py and custom.py\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation dataset\n",
    "dataset = custom.CustomDataset() #Raju: for bridge change \"custom_matc\" to \"custom\"\n",
    "dataset.load_custom(custom_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the last model you trained\n",
    "# weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", custom_WEIGHTS_PATH)\n",
    "model.load_weights(custom_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following line is only for the detection code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My original detection code: (Without temporal coherence)\n",
    "#-------------------------------------------------------------\n",
    "# Test results will be saved in the following directory\n",
    "testresult = 'C:/Users/mk5n2/Mask/Inspire/CustomImages/test/testresult/precision_previous/'\n",
    "\n",
    "# Images from the following directory will be tested\n",
    "test_dir ='C:/Users/mk5n2/Mask/Inspire/CustomImages/test/test_dir/precision/'\n",
    "\n",
    "# Creating a list with the names of all the test images from the test_dir\n",
    "testfiles= os.listdir(test_dir)\n",
    "testfiles = testfiles[4:6]\n",
    "\n",
    "#looping through all images in the test_dir\n",
    "for i in range(len(testfiles)):\n",
    "    filename= os.path.join(test_dir,testfiles[i])\n",
    "    image = skimage.io.imread(filename)\n",
    "    \n",
    "    #Run Detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    \n",
    "    #Display results\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "#     plt.savefig(testresult+testfiles[i])  \n",
    "\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision_recall only in Mask RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "from mrcnn import utils\n",
    "# Test results will be saved in the following directory\n",
    "from mrcnn import visualize_frame_relation_4f\n",
    "testresult = 'C:/Users/mk5n2/Mask/Inspire/CustomImages/test/testresult/precision_train_1/'\n",
    "\n",
    "# Images from the following directory will be tested\n",
    "test_dir = 'C:/Users/mk5n2/Mask/Inspire/CustomImages/test/test_dir/precision_train_1/'\n",
    "\n",
    "# Creating a list with the names of all the test images in the test_dir\n",
    "testfiles= os.listdir(test_dir)\n",
    "# testfiles = testfiles[3:4]\n",
    "# in the 'c' variable we will store class_ids after every three images\n",
    "c=[]\n",
    "a=[]\n",
    "d=[]\n",
    "e=[]\n",
    "# s will store prediction score of joint\n",
    "s=[]\n",
    "# ita will store every iteration number\n",
    "ita=[]\n",
    "Xcor=[]\n",
    "Ycor=[]\n",
    "Xcor3=[]\n",
    "Ycor3=[]\n",
    "Xcor4=[]\n",
    "Ycor4=[]\n",
    "Xcor5=[]\n",
    "Ycor5=[]\n",
    "for i, name in enumerate(testfiles):\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset, config,\n",
    "                           i, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "    \n",
    "    filename= os.path.join(test_dir,testfiles[i])\n",
    "#     image = skimage.io.imread(filename)\n",
    "    file = testfiles[i]\n",
    "    filesize = os.path.getsize(filename)\n",
    "    \n",
    "    #Run Detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    \n",
    "    #Display results\n",
    "#     ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    class_ids = r['class_ids']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    roi = r['rois']\n",
    "    t_roi = zip(*roi) #transpose roi\n",
    "    converted = list(t_roi) # converted to list from zip\n",
    "    Xc= converted[1] # X coordinate of all objects will be stored \n",
    "    Yc= converted[0] # Y coordinate of all objects will be stored\n",
    "    \n",
    "    mapped = zip(scores, class_ids,Xc,Yc)\n",
    "    mapped = list(mapped)\n",
    "    gt_match, pred_match,overlaps =utils.compute_precision_recall_old_version(file,gt_bbox, gt_class_id, gt_mask,\n",
    "                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     visualize_frame_relation_4f.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "#                             dataset.class_names, r['scores'], ax=ax,\n",
    "#                             title=\"Predictions\")\n",
    "    \n",
    "    # new variable 'a' is defined\n",
    "    # after every two images this 'a' variable will store the class_id for that image\n",
    "    print(class_ids, 'for i =', i)\n",
    "    print(scores, 'for i =', i)\n",
    "    print(filename)\n",
    "      \n",
    "\n",
    "frequency = 3500  # Set Frequency To 2500 Hertz\n",
    "duration = 100  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Code with temporal coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detection Code with temporal coherence\n",
    "import winsound\n",
    "from mrcnn import visualize_frame_relation_4f\n",
    "testresult = 'C:/Users/mk5n2/Mask/Inspire/CustomImages/test/testresult/iteration_1_supervised/'\n",
    "\n",
    "# Images from the following directory will be tested\n",
    "test_dir ='C:/Users/mk5n2/Mask/Inspire/CustomImages/test/test_dir/10frames_bridgeC_part1/'\n",
    "\n",
    "# Creating a list with the names of all the test images in the test_dir\n",
    "testfiles= os.listdir(test_dir)\n",
    "# testfiles = testfiles[0:3]\n",
    "# in the 'c' variable we will store class_ids after every three images\n",
    "c=[]\n",
    "a=[]\n",
    "b=[]\n",
    "d=[]\n",
    "e=[]\n",
    "# s will store prediction score of joint\n",
    "s=[]\n",
    "# ita will store every iteration number\n",
    "ita=[]\n",
    "Xcor1=[]\n",
    "Ycor1=[]\n",
    "Xcor2=[]\n",
    "Ycor2=[]\n",
    "Xcor3=[]\n",
    "Ycor3=[]\n",
    "Xcor4=[]\n",
    "Ycor4=[]\n",
    "Xcor5=[]\n",
    "Ycor5=[]\n",
    "\n",
    "for i in range(0,len(testfiles)):\n",
    "    filename= os.path.join(test_dir,testfiles[i])\n",
    "    image = skimage.io.imread(filename)\n",
    "    file = testfiles[i]\n",
    "    filesize = os.path.getsize(filename)\n",
    "    \n",
    "    #Run Detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    \n",
    "    #Display results\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    class_ids = r['class_ids']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    roi = r['rois']\n",
    "    t_roi = zip(*roi) #transpose roi\n",
    "    converted = list(t_roi) # converted to list from zip\n",
    "    if converted == []:\n",
    "        Xc = []\n",
    "        Yc = []\n",
    "    else:\n",
    "        Xc = converted[1]\n",
    "        Yc = converted[0]\n",
    "#     Xc= converted[1] # X coordinate of all objects will be stored \n",
    "#     Yc= converted[0] # Y coordinate of all objects will be stored\n",
    "    \n",
    "    mapped = zip(scores, class_ids,Xc,Yc)\n",
    "    mapped = list(mapped)\n",
    "    print(\"---\")\n",
    "    print(i)\n",
    "    print(file)\n",
    "    \n",
    "    # new variable 'a' is defined\n",
    "    # after every two images this 'a' variable will store the class_id for that image\n",
    "    \n",
    "    \n",
    "    if i in range(0,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f1'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_annotation(f_ref,image,file,filename,filesize, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        a= cl\n",
    "        Xcor1 = Xco\n",
    "        Ycor1 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "        \n",
    "        \n",
    "    elif i in range(1,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f2'\n",
    "        print(f_ref)        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_annotation(f_ref,image,file,filename,filesize, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        b= cl\n",
    "        Xcor2 = Xco\n",
    "        Ycor2 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "        \n",
    "    elif i in range(2,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f3'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_annotation(f_ref,image,file,filename,filesize, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        c= cl\n",
    "        Xcor3 = Xco\n",
    "        Ycor3 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "        \n",
    "    elif i in range(3,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[] \n",
    "        f_ref = 'f4'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_annotation(f_ref,image,file,filename,filesize, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        d= cl\n",
    "        Xcor4 = Xco\n",
    "        Ycor4 = Yco\n",
    "       \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "\n",
    "    elif i in range(4,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f5'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_annotation(f_ref,image,file,filename,filesize, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        e= cl\n",
    "        Xcor5 = Xco\n",
    "        Ycor5 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1200  # Set Duration To 1000 ms == 1 second\n",
    "# winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detection Code with temporal coherence\n",
    "import winsound\n",
    "from mrcnn import visualize_frame_relation_4f\n",
    "testresult = 'C:/Users/mk5n2/Mask_RCNN/CustomImages/test/test_result/0th_iteration/'\n",
    "\n",
    "# Images from the following directory will be tested\n",
    "test_dir ='C:/Users/mk5n2/Mask_RCNN/CustomImages/test/test_dir/10frames_bridgeC_part1/'\n",
    "\n",
    "# Creating a list with the names of all the test images in the test_dir\n",
    "testfiles= os.listdir(test_dir)\n",
    "# testfiles = testfiles[567:578]\n",
    "# in the 'c' variable we will store class_ids after every three images\n",
    "c=[]\n",
    "a=[]\n",
    "b=[]\n",
    "d=[]\n",
    "e=[]\n",
    "# s will store prediction score of joint\n",
    "s=[]\n",
    "# ita will store every iteration number\n",
    "ita=[]\n",
    "Xcor1=[]\n",
    "Ycor1=[]\n",
    "Xcor2=[]\n",
    "Ycor2=[]\n",
    "Xcor3=[]\n",
    "Ycor3=[]\n",
    "Xcor4=[]\n",
    "Ycor4=[]\n",
    "Xcor5=[]\n",
    "Ycor5=[]\n",
    "json1 ={}\n",
    "for i in range(0,len(testfiles)):\n",
    "    filename= os.path.join(test_dir,testfiles[i])\n",
    "    image = skimage.io.imread(filename)\n",
    "    file = testfiles[i]\n",
    "    filesize = os.path.getsize(filename)\n",
    "    \n",
    "    #Run Detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    \n",
    "    #Display results\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    class_ids = r['class_ids']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    roi = r['rois']\n",
    "    t_roi = zip(*roi) #transpose roi\n",
    "    converted = list(t_roi) # converted to list from zip\n",
    "    if converted == []:\n",
    "        Xc = []\n",
    "        Yc = []\n",
    "    else:\n",
    "        Xc = converted[1]\n",
    "        Yc = converted[0]\n",
    "#     Xc= converted[1] # X coordinate of all objects will be stored \n",
    "#     Yc= converted[0] # Y coordinate of all objects will be stored\n",
    "    \n",
    "    mapped = zip(scores, class_ids,Xc,Yc)\n",
    "    mapped = list(mapped)\n",
    "    print(\"---\")\n",
    "    print(i)\n",
    "    print(file)\n",
    "    \n",
    "    # new variable 'a' is defined\n",
    "    # after every two images this 'a' variable will store the class_id for that image\n",
    "    \n",
    "    \n",
    "    if i in range(0,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f1'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "        print('before iteration f1: ',cl)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_json(f_ref,image,file,filename,filesize,json1, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        a= cl\n",
    "        print('after iteration f1: ', a)\n",
    "        Xcor1 = Xco\n",
    "        Ycor1 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "        \n",
    "        \n",
    "    elif i in range(1,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f2'\n",
    "        print(f_ref)        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "        print('before iteration f2: ',cl)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_json(f_ref,image,file,filename,filesize,json1, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        b= cl\n",
    "        print('after iteration f2: ', b)\n",
    "        Xcor2 = Xco\n",
    "        Ycor2 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "        \n",
    "    elif i in range(2,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f3'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_json(f_ref,image,file,filename,filesize,json1, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        c= cl\n",
    "        Xcor3 = Xco\n",
    "        Ycor3 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "        \n",
    "    elif i in range(3,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[] \n",
    "        f_ref = 'f4'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_json(f_ref,image,file,filename,filesize,json1, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        d= cl\n",
    "        Xcor4 = Xco\n",
    "        Ycor4 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "\n",
    "    elif i in range(4,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f5'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        visualize_frame_relation_4f.display_instances_5f_for_json(f_ref,image,file,filename,filesize,json1, r['rois'], r['masks'], r['class_ids'], \n",
    "                        dataset.class_names,a,b,c,d,e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5, r['scores'], ax=ax,\n",
    "                        title=\"Predictions\")\n",
    "        e= cl\n",
    "        Xcor5 = Xco\n",
    "        Ycor5 = Yco\n",
    "        \n",
    "        plt.savefig(testresult+testfiles[i])\n",
    "\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1200  # Set Duration To 1000 ms == 1 second\n",
    "# winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision_recall with temporal coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_recall with temporal coherence\n",
    "import winsound\n",
    "from mrcnn import visualize_frame_relation_4f\n",
    "testresult = 'C:/Users/mk5n2/Mask/Inspire/CustomImages/test/testresult/precision_train_1/'\n",
    "\n",
    "# Images from the following directory will be tested\n",
    "# test_dir = os.path.join(ROOT_DIR, \"CustomImages/test/test_dir/10frames_bridgeC_part1/\")\n",
    "test_dir = 'C:/Users/mk5n2/Mask/Inspire/CustomImages/test/test_dir/precision_train_1/'\n",
    "\n",
    "# Creating a list with the names of all the test images in the test_dir\n",
    "testfiles= os.listdir(test_dir)\n",
    "# testfiles = testfiles[184:210]\n",
    "# in the 'c' variable we will store class_ids after every three images\n",
    "c=[]\n",
    "a=[]\n",
    "b=[]\n",
    "d=[]\n",
    "e=[]\n",
    "# s will store prediction score of joint\n",
    "s=[]\n",
    "# ita will store every iteration number\n",
    "ita=[]\n",
    "Xcor1=[]\n",
    "Ycor1=[]\n",
    "Xcor2=[]\n",
    "Ycor2=[]\n",
    "Xcor3=[]\n",
    "Ycor3=[]\n",
    "Xcor4=[]\n",
    "Ycor4=[]\n",
    "Xcor5=[]\n",
    "Ycor5=[]\n",
    "for i in range(0,len(testfiles)):\n",
    "    filename= os.path.join(test_dir,testfiles[i])\n",
    "    image = skimage.io.imread(filename)\n",
    "    file = testfiles[i]\n",
    "    \n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset, config,\n",
    "                           i, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "    filesize = os.path.getsize(filename)\n",
    "    \n",
    "    #Run Detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    \n",
    "    #Display results\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    class_ids = r['class_ids']\n",
    "    scores = r['scores']\n",
    "    \n",
    "    roi = r['rois']\n",
    "    t_roi = zip(*roi) #transpose roi\n",
    "    converted = list(t_roi) # converted to list from zip\n",
    "    if converted == []:\n",
    "        Xc = []\n",
    "        Yc = []\n",
    "    else:\n",
    "        Xc = converted[1]\n",
    "        Yc = converted[0]\n",
    "#     Xc= converted[1] # X coordinate of all objects will be stored \n",
    "#     Yc= converted[0] # Y coordinate of all objects will be stored\n",
    "    \n",
    "    mapped = zip(scores, class_ids,Xc,Yc)\n",
    "    mapped = list(mapped)\n",
    "    print(\"---\")\n",
    "    print(i)\n",
    "    print(file)\n",
    "    \n",
    "    # new variable 'a' is defined\n",
    "    # after every two images this 'a' variable will store the class_id for that image\n",
    "    \n",
    "    \n",
    "    if i in range(0,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f1'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        gt_match, pred_match,overlaps =utils.compute_precision_recall_old_18_march(f_ref, file,gt_bbox, gt_class_id, gt_mask,\n",
    "                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],a,b, c, d, e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5)\n",
    "        a= cl\n",
    "        Xcor1 = Xco\n",
    "        Ycor1 = Yco\n",
    "        \n",
    "        \n",
    "    elif i in range(1,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f2'\n",
    "        print(f_ref)        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        gt_match, pred_match,overlaps =utils.compute_precision_recall_old_18_march(f_ref, file,gt_bbox, gt_class_id, gt_mask,\n",
    "                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],a,b, c, d, e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5)\n",
    "        b= cl\n",
    "        Xcor2 = Xco\n",
    "        Ycor2 = Yco\n",
    "        \n",
    "        \n",
    "    elif i in range(2,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f3'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        gt_match, pred_match,overlaps =utils.compute_precision_recall_old_18_march(f_ref, file,gt_bbox, gt_class_id, gt_mask,\n",
    "                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],a,b, c, d, e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5)\n",
    "        c= cl\n",
    "        Xcor3 = Xco\n",
    "        Ycor3 = Yco\n",
    "\n",
    "        \n",
    "    elif i in range(3,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[] \n",
    "        f_ref = 'f4'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        gt_match, pred_match,overlaps =utils.compute_precision_recall_old_18_march(f_ref, file,gt_bbox, gt_class_id, gt_mask,\n",
    "                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],a,b, c, d, e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5)\n",
    "        d= cl\n",
    "        Xcor4 = Xco\n",
    "        Ycor4 = Yco\n",
    "\n",
    "\n",
    "    elif i in range(4,len(testfiles),5):\n",
    "        sc=[] #this will store scores\n",
    "        cl=[] # this will store class_ids\n",
    "        Xco =[]\n",
    "        Yco =[]\n",
    "        f_ref = 'f5'\n",
    "        print(f_ref)\n",
    "        \n",
    "#       this loop will eliminate all scores below 0.9 and will save remaining class_ids in cl\n",
    "        for k,l,m,n in mapped:\n",
    "            if k<0.9:\n",
    "                continue\n",
    "            sc.append(k)\n",
    "            cl.append(l)\n",
    "            Xco.append(m)\n",
    "            Yco.append(n)\n",
    "\n",
    "        gt_match, pred_match,overlaps =utils.compute_precision_recall_old_18_march(f_ref, file,gt_bbox, gt_class_id, gt_mask,\n",
    "                     r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],a,b, c, d, e,cl,Xco,Yco,Xcor1,Ycor1,Xcor2,Ycor2,Xcor3,Ycor3,Xcor4,Ycor4,Xcor5,Ycor5)\n",
    "        e= cl\n",
    "        Xcor5 = Xco\n",
    "        Ycor5 = Yco\n",
    "        \n",
    "\n",
    "frequency = 3500  # Set Frequency To 2500 Hertz\n",
    "duration = 1500  # Set Duration To 1000 ms == 1 second\n",
    "# winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mAP calculation in mask rcnn without temporal coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "#mAP calculation:\n",
    "image_ids = os.listdir('C:/Users/mk5n2/Mask/Inspire/CustomImages/test/test_dir/pre_recall_curve/')\n",
    "# image_ids = image_ids[58:60]\n",
    "image_ids\n",
    "APs =[]\n",
    "\n",
    "for image_id, name in enumerate(image_ids):\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset, config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n",
    "    # Run object detection\n",
    "\n",
    "    results = model.detect([image], verbose=0)\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "    \n",
    "#     # Compute AP over range 0.5 to 0.95 and print it\n",
    "#     utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "#                            r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "#                            verbose=1)\n",
    "\n",
    "# #     visualize.display_differences(\n",
    "# #         image,\n",
    "# #         gt_bbox, gt_class_id, gt_mask,\n",
    "# #         r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "# #         dataset.class_names, ax=get_ax(),\n",
    "# #         show_box=False, show_mask=False,\n",
    "# #         iou_threshold=0.5, score_threshold=0.5)\n",
    "#     # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     print(\"AP : \",AP , \"for image id: \", image_id)\n",
    "\n",
    "# #     print(\"precisions :\", precisions)\n",
    "# #     print(\"recalls :\", recalls)\n",
    "# #     print(\"overlaps :\", overlaps)\n",
    "#     APs.append(AP)\n",
    "    \n",
    "# print(\"mAP: \", np.mean(APs))\n",
    "# print (APs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw precision-recall curve\n",
    "AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "visualize.plot_precision_recall(AP, precisions, recalls)\n",
    "print('precisions: ',precisions)\n",
    "print('recalls: ',recalls)\n",
    "print(AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of ground truth objects and their predictions\n",
    "visualize_frame_relation_4f.plot_overlaps(gt_class_id, r['class_ids'], r['scores'],\n",
    "                        overlaps, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below code are obsolete (18 March,2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
